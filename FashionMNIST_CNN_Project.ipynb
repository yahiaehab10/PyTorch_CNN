{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Convolution Neural Network(CNN)\n",
    "\n",
    "Known for their capabilities to find patterns in visual data\n",
    "\n",
    "CNN explainer: https://poloclub.github.io/cnn-explainer/. Check the hyper params in here\n",
    "\n",
    "We will replicate what is going on there "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FashionMNIST Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion MNIST dataset\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None,  # optional transform to be applied to the target\n",
    ")\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None,  # optional transform to be applied to the target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Sample of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random 5 images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 15))\n",
    "for i in range(5):\n",
    "    idx = np.random.randint(0, len(train_data))\n",
    "    image, label = train_data[idx]\n",
    "    axes[i].imshow(image.squeeze(), cmap=\"gray\")\n",
    "    axes[i].set_title(train_data.classes[label])\n",
    "    axes[i].axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Constant Batch Size(Samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "BATCH_SIZE = 32  # meaning 32 images in a batch: 32 images are processed in parallel\n",
    "train_loader = th.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_loader = th.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(len(train_loader), len(test_loader))  # 1875 313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make device agnostic\n",
    "if th.backends.mps.is_available():\n",
    "    device = th.device(\"mps\")\n",
    "    print(\"MPS device found.\")\n",
    "else:\n",
    "    device = th.device(\"cpu\")\n",
    "    print(\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Model Architecture that replicates the TinyVGG model from CNN explainer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        \"\"\"\n",
    "        Initialize the model architecture.\n",
    "        :param input_shape: The shape of the input data.\n",
    "        :param hidden_units: The number of hidden units in the model.\n",
    "        :param output_shape: The shape of the output data.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=input_shape,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(\n",
    "                7 * 7 * hidden_units, 128\n",
    "            ),  # 7*7*hidden_units is the size of the image after the convolutions because of the maxpooling layers\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_shape),\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        The output of the convolutions block 2\n",
    "        it goes into the classifier and gets flattened,\n",
    "        so this line `nn.Linear(7*7*hidden_units, 128)`\n",
    "        is 7*7*hidden_units, because it is the output shape of the convolutions block 2,\n",
    "        which is [1, 64, 7, 7] and 7*7*64 = 3136. 64 is the number of hidden units.\n",
    "        To know the 7*7, we need to know the output shape of the convolutions \n",
    "        by using this predefined method: `self._get_conv_output(input_shape)`\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "        :param x: The input data.\n",
    "        :return: The output data.\n",
    "\n",
    "        As an image through layers\n",
    "        \"\"\"\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_data[0]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(42)\n",
    "model = FashionMNISTModel(1, 10, len(train_data.classes)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(42)\n",
    "\n",
    "# Creating batches of images \n",
    "images = th.randn(size=(32, 3, 64, 64))\n",
    "test_images = images[0]\n",
    "\n",
    "print(f'Images batch shape: {images.shape}')\n",
    "print(f'Image shape: {test_images.shape}')\n",
    "print(f'Model Dict: {model.state_dict().keys()}')\n",
    "print(f'Image Image:\\n {test_images}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create single conv2d layer\n",
    "conv_layer = nn.Conv2d(in_channels=3, # Equivalent is the same as color channels\n",
    "                       out_channels=10, # Equivalent to the number of hidden units(filters)\n",
    "                       kernel_size=3, # 3 x 3 kernel size.  Equivalent to the size of the filter\n",
    "                       stride=1, # Equivalent to the step size of the filter\n",
    "                       padding=1) # Equivalent to the padding of the filter\n",
    "\n",
    "conv_output = conv_layer(test_images.unsqueeze(0)) # Unsqueeze to add a batch dimension, because conv2d expects a batch dimension\n",
    "print(f'Conv Output Shape: {conv_output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stepping through `nn.MaxPool2d()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Original Image Shape: {test_images.shape}')\n",
    "print(f'Unsqueeze Image Shape: {test_images.unsqueeze(0).shape}')\n",
    "\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2) \n",
    "\"\"\"\n",
    "if we change to 4, we will have th.Size([1, 10, 16, 16]) \n",
    "as it is the max value of the 4x4 grid not the 2x2 grid\n",
    "\"\"\"\n",
    "\n",
    "print()\n",
    "\n",
    "# Pass data through just the conv layer\n",
    "test_image_through_conv = conv_layer(test_images.unsqueeze(0))\n",
    "print(f'Conv Output Shape: {test_image_through_conv.shape}')\n",
    "\n",
    "print()\n",
    "\n",
    "# Pass data through conv layer and max pool layer\n",
    "test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)\n",
    "print(f'Max Pool Output Shape: {test_image_through_conv_and_max_pool.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up loss function/evaluation metric/optimizer\n",
    "# from helper_functions import accuracy_fn, train_step, test_step, print_train_time\n",
    "import tqdm\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = th.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(42)\n",
    "\n",
    "\n",
    "def eval_model(\n",
    "    model: th.nn.Module,\n",
    "    data_loader: th.utils.data.DataLoader,\n",
    "    loss_fn: th.nn.Module,\n",
    "    accuracy_fn,\n",
    "):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
    "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
    "        loss_fn (torch.nn.Module): The loss function of model.\n",
    "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Results of model making predictions on data_loader.\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with th.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Make predictions with the model\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Accumulate the loss and accuracy values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(\n",
    "                y_true=y, y_pred=y_pred.argmax(dim=1)\n",
    "            )  # For accuracy, need the prediction labels (logits -> pred_prob -> pred_labels)\n",
    "\n",
    "        # Scale loss and acc to find the average loss/acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    return {\n",
    "        \"model_name\": model.__class__.__name__,  # only works when model was created with a class\n",
    "        \"model_loss\": loss.item(),\n",
    "        \"model_acc\": acc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make device agnostic\n",
    "if th.backends.mps.is_available():\n",
    "    device = th.device(\"mps\")\n",
    "    print(\"MPS device found.\")\n",
    "else:\n",
    "    device = th.device(\"cpu\")\n",
    "    print(\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    model: th.nn.Module,\n",
    "    data_loader: th.utils.data.DataLoader,\n",
    "    loss_fn: th.nn.Module,\n",
    "    optimizer: th.optim.Optimizer,\n",
    "    accuracy_fn,\n",
    "    device: th.device = device,\n",
    "):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # Send data to GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(\n",
    "            y_true=y, y_pred=y_pred.argmax(dim=1)\n",
    "        )  # Go from logits -> pred labels\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"\\rTrain loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "\n",
    "def test_step(\n",
    "    data_loader: th.utils.data.DataLoader,\n",
    "    model: th.nn.Module,\n",
    "    loss_fn: th.nn.Module,\n",
    "    accuracy_fn,\n",
    "    device: th.device = device,\n",
    "):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval()  # put model in eval mode\n",
    "    # Turn on inference context manager\n",
    "    with th.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            # Send data to GPU\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(\n",
    "                y_true=y,\n",
    "                y_pred=test_pred.argmax(dim=1),  # Go from logits -> pred labels\n",
    "            )\n",
    "\n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"\\rTest loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "\n",
    "# Print Training Time Function\n",
    "def print_train_time(\n",
    "    start: int,\n",
    "    end: int,\n",
    "    device: th.device = None,\n",
    "):\n",
    "    \"\"\"Prints the time elapsed during training.\n",
    "    Args:\n",
    "        start (int): Start time in seconds.\n",
    "        end (int): End time in seconds.\n",
    "        device (th.device): Device used to train the model (default: None).\n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Total time elapsed: {total_time} seconds.\")\n",
    "    return total_time\n",
    "\n",
    "\n",
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (torch.Tensor): Truth labels for predictions.\n",
    "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
    "\n",
    "    Returns:\n",
    "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
    "    \"\"\"\n",
    "    correct = th.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.manual_seed(42)\n",
    "\n",
    "# Measure the time it takes to train the model\n",
    "from timeit import default_timer as timer\n",
    "import tqdm\n",
    "\n",
    "train_time_start_model = timer()\n",
    "\n",
    "# Train the model\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch+1}\\n-------------------------------')\n",
    "    train_step(\n",
    "        model = model,\n",
    "        data_loader=train_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        optimizer=optimizer,\n",
    "        device=device\n",
    "    )\n",
    "    test_step(\n",
    "        model=model,\n",
    "        data_loader=test_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    print()\n",
    "\n",
    "train_time_end_model = timer()\n",
    "\n",
    "total_train_time_model = print_train_time(train_time_start_model, train_time_end_model,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "model_results = eval_model(\n",
    "    model=model,\n",
    "    data_loader=test_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_fn\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model: th.nn.Module, data: list, device: th.device = device):\n",
    "    pred_probs = []\n",
    "    model.eval()\n",
    "    with th.inference_mode():\n",
    "        for sample in data:\n",
    "            # Prepare sample\n",
    "            sample = th.unsqueeze(sample, dim=0).to(\n",
    "                device\n",
    "            )  # Add an extra dimension and send sample to device\n",
    "\n",
    "            # Forward pass (model outputs raw logit)\n",
    "            pred_logit = model(sample)\n",
    "\n",
    "            # Get prediction probability (logit -> prediction probability)\n",
    "            pred_prob = th.softmax(\n",
    "                pred_logit.squeeze(), dim=0\n",
    "            )  # note: perform softmax on the \"logits\" dimension, not \"batch\" dimension (in this case we have a batch size of 1, so can perform on dim=0)\n",
    "\n",
    "            # Get pred_prob off GPU for further calculations\n",
    "            pred_probs.append(pred_prob.cpu())\n",
    "\n",
    "    # Stack the pred_probs to turn list into a tensor\n",
    "    return th.stack(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# random.seed(42)\n",
    "\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "for sample, label in random.sample(list(test_data), 9):\n",
    "    test_samples.append(sample)\n",
    "    test_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test samples\n",
    "pred_prob = make_predictions(model=model,\n",
    "                             data=test_samples,\n",
    "                             device=device)\n",
    "\n",
    "# Get the predicted labels\n",
    "pred_labels = pred_prob.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predictions\n",
    "plt.figure(figsize=(7, 8))\n",
    "n_rows, n_cols = 3, 3\n",
    "for i, (sample, label, pred_label) in enumerate(\n",
    "    zip(test_samples, test_labels, pred_labels)\n",
    "):\n",
    "    plt.subplot(n_rows, n_cols, i + 1)\n",
    "    plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
    "    if label == pred_label:\n",
    "        plt.title(\n",
    "            f\"Label: {test_data.classes[label]} \\n Prediction: {test_data.classes[pred_label]}\",\n",
    "            color=\"green\",\n",
    "        )\n",
    "    else:\n",
    "        plt.title(\n",
    "            f\"Label: {test_data.classes[label]} \\n Prediction: {test_data.classes[pred_label]}\",\n",
    "            color=\"red\",\n",
    "        )\n",
    "    plt.axis(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a confusion matrix for further prediction evaluation:\n",
    "\n",
    "1. Make predictions with our trained model on test dataset\n",
    "2. Make a confusion matrix `torchmatrics.ConfusionMatrix`\n",
    "3. Plot confusion matrix using `mlxtend.plotting.plot_confusion_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. Make predictions with trained model\n",
    "y_preds = []\n",
    "model.eval()\n",
    "with th.inference_mode():\n",
    "    for X_batch, y_batch in tqdm(test_loader):\n",
    "        # Send data to GPU\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        # Get predicted class\n",
    "        y_pred = th.argmax(y_pred, dim=1)\n",
    "\n",
    "        # Append batch predictions to list\n",
    "        y_preds.extend(y_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "# 2. Create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true=test_data.targets, y_pred=y_preds)\n",
    "\n",
    "# 3. Plot confusion matrix\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                            normalize=False,\n",
    "                            title='Confusion matrix',\n",
    "                            cmap=plt.cm.Blues,\n",
    "                            figsize=(10, 10),\n",
    "                            savefig=False):\n",
    "        \"\"\"\n",
    "        This function prints and plots the confusion matrix.\n",
    "        Normalization can be applied by setting `normalize=True`.\n",
    "        \"\"\"\n",
    "        # Create the figure and axes objects\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "        # Create the confusion matrix\n",
    "        cm = confusion_matrix(y_true=test_data.targets, y_pred=y_preds)\n",
    "    \n",
    "        # Normalization option\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "        # Plot the confusion matrix\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    \n",
    "        # Customize the plot\n",
    "        ax.set(title=title,\n",
    "             xlabel=\"Predicted label\",\n",
    "             ylabel=\"True label\",\n",
    "             xticks=np.arange(len(classes)),\n",
    "             yticks=np.arange(len(classes)),\n",
    "             xticklabels=classes,\n",
    "             yticklabels=classes,\n",
    "             ylim=[len(classes) - 0.5, -0.5],\n",
    "             aspect=\"equal\")\n",
    "    \n",
    "        # Rotate the xticks\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                 rotation_mode=\"anchor\")\n",
    "    \n",
    "        # Loop through and add the confusion matrix numbers as text annotations\n",
    "        fmt = \".2f\" if normalize else \"d\"\n",
    "        thresh = cm.max() / 2.0  # Used for text coloring below\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    fontsize=15,\n",
    "                    horizontalalignment=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "        # Add a legend\n",
    "        fig.colorbar(im)\n",
    "    \n",
    "        # Save the figure is savefig is True\n",
    "        if savefig:\n",
    "            fig.savefig(title.lower().replace(\" \", \"_\") + \".png\")\n",
    "\n",
    "        return ax\n",
    "\n",
    "# Define the labels of the class indices (different from the actual class names)\n",
    "class_names = []\n",
    "\n",
    "for i in range(10):\n",
    "     class_names.append(test_data.classes[i])\n",
    "\n",
    "plot_confusion_matrix(cm=cm, classes=class_names, normalize=True, title=\"Confusion Matrix\", savefig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Get classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate a classification report\n",
    "class_report = classification_report(y_true=test_data.targets,\n",
    "                                     y_pred=y_preds)\n",
    "\n",
    "print(class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
